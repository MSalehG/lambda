{
  "batch": {
    "sparkConf":[["spark.sql.files.maxPartitionBytes","6m"], ["spark.sql.shuffle.partitions","8"]],
    "csvPath": "/job/source.csv",
    "url": "jdbc:postgresql://localhost:5432/my_database",
    "user": "postgres",
    "password": "postgres",
    "numPartitions": "4",
    "partitionColumn": "id"
  }
}